{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtB56n+xTdh6lG1mMYBWr/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpraveen123/IT7103/blob/main/praveen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3U8RaUQ9ODgi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/auto-mpg.csv')\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYiJ8ttn5-RS",
        "outputId": "2b1837ed-45b1-4397-dac9-ca2d75147483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "mpg             float64\n",
            "cylinders         int64\n",
            "displacement    float64\n",
            "horsepower      float64\n",
            "weight            int64\n",
            "acceleration    float64\n",
            "model year        int64\n",
            "origin            int64\n",
            "car name         object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Praveen Durvesula - 001096680\n",
        "# Subject Code - IT 7103"
      ],
      "metadata": {
        "id": "E7gY9gazOPIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\n",
        "from scipy.stats import skew\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load the data into a Pandas DataFrame and check data\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/auto-mpg.csv')\n",
        "\n",
        "# df = pd.read_csv('auto-mpg.csv')\n",
        "\n",
        "# Check data types\n",
        "print(df.dtypes)\n",
        "\n",
        "# 2. Split the data into training and testing sets (75% training, 25% testing)\n",
        "\n",
        "# Create a histogram to visualize the distribution\n",
        "\n",
        "# plt.hist(data['acceleration'], bins=100, density=True, alpha=0.6, color='b')\n",
        "\n",
        "# # Add labels and a title\n",
        "# plt.xlabel('Value')\n",
        "# plt.ylabel('Probability Density')\n",
        "# plt.title('Symmetric Distribution from CSV Data')\n",
        "\n",
        "Feature = df.drop(columns=['mpg'])  # Features\n",
        "Target = df['mpg']  # Target variable\n",
        "\n",
        "Feature_train, Feature_test, Target_train, Target_test = train_test_split(Feature, Target, test_size=0.25, random_state=42)\n",
        "\n",
        "# 3. Visualize and categorize columns\n",
        "\n",
        "# The skewness values you've calculated using the .skew() method provide insights into the distribution of each numeric column in your dataset.\n",
        "# Positive skewness indicates a right-skewed distribution, while negative skewness indicates a left-skewed distribution.\n",
        "# Here's how to interpret and categorize these columns:\n",
        "\n",
        "print(df['cylinders'].skew(),df['displacement'].skew(),df['horsepower'].skew(),df['weight'].skew(),df['acceleration'].skew(),df['model year'].skew(),df['origin'].skew())\n",
        "\n",
        "numeric_symmetric_cols = ['cylinders', 'weight', 'acceleration','model year']\n",
        "numeric_skewed_cols = ['displacement', 'horsepower', 'origin']\n",
        "categorical_cols = ['car name']\n",
        "\n",
        "# 4. Build a pipeline\n",
        "numeric_symmetric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "\n",
        "numeric_skewed_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('log_transform', FunctionTransformer(np.log1p, validate=False)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num_symmetric', numeric_symmetric_transformer, numeric_symmetric_cols),\n",
        "        ('num_skewed', numeric_skewed_transformer, numeric_skewed_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
        "\n",
        "# 5. Train the pipeline on the training data and perform transformations\n",
        "Feature_train_processed = pipeline.fit_transform(Feature_train)\n",
        "Feature_test_processed = pipeline.transform(Feature_test)\n",
        "\n",
        "# 6. Print the shape of the processed data\n",
        "print(\"Shape of processed training data:\", Feature_train_processed.shape)\n",
        "print(\"Shape of processed testing data:\", Feature_test_processed.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1yuhBNN-5HX",
        "outputId": "49f1ce09-3849-4625-cca3-83ee4abad0a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "mpg             float64\n",
            "cylinders         int64\n",
            "displacement    float64\n",
            "horsepower      float64\n",
            "weight            int64\n",
            "acceleration    float64\n",
            "model year        int64\n",
            "origin            int64\n",
            "car name         object\n",
            "dtype: object\n",
            "0.5269215453528939 0.7196451643005952 1.0873262824048695 0.5310625125994629 0.27877684462588986 0.01153459401509278 0.9237762994760227\n",
            "Shape of processed training data: (298, 239)\n",
            "Shape of processed testing data: (100, 239)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment - 3**"
      ],
      "metadata": {
        "id": "-SaHEw96JTEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#connecting with google drive and getting csv file from drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "data = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/stroke.csv')\n",
        "print(data.dtypes)\n",
        "# Check for missing values\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHW-aUzCJE9w",
        "outputId": "e37d07e5-3422-4b31-8060-c96cc865b19e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "id                     int64\n",
            "gender                object\n",
            "age                  float64\n",
            "hypertension           int64\n",
            "heart_disease          int64\n",
            "ever_married          object\n",
            "work_type             object\n",
            "Residence_type        object\n",
            "avg_glucose_level    float64\n",
            "bmi                  float64\n",
            "smoking_status        object\n",
            "stroke                 int64\n",
            "dtype: object\n",
            "id                     0\n",
            "gender                 0\n",
            "age                    0\n",
            "hypertension           0\n",
            "heart_disease          0\n",
            "ever_married           0\n",
            "work_type              0\n",
            "Residence_type         0\n",
            "avg_glucose_level      0\n",
            "bmi                  201\n",
            "smoking_status         0\n",
            "stroke                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Handle missing values\n",
        "# Example: Replace missing values in 'bmi' column with the mean\n",
        "data['bmi'].fillna(data['bmi'].mean(), inplace=True)\n",
        "\n",
        "# Convert categorical variables to numerical using one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "# Drop 'id' column\n",
        "data.drop('id', axis=1, inplace=True)\n",
        "\n",
        "# Check the updated data\n",
        "# The three classifications models are\n",
        "\n",
        "# Model 1: Logistic Regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop('stroke', axis=1)\n",
        "y = data['stroke']\n",
        "\n",
        "# Split the data into training and testing sets, 80% of data is used for training and 20% is used for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "logreg_model = LogisticRegression()\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting\n",
        "y_pred_logreg = logreg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "classification_report_logreg = classification_report(y_test, y_pred_logreg)\n",
        "\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_logreg}\")\n",
        "print(\"Classification Report for Logistic Regression:\")\n",
        "print(classification_report_logreg)\n",
        "\n",
        "# Model:2 Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize and train the Decision Tree model\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "classification_report_dt = classification_report(y_test, y_pred_dt)\n",
        "\n",
        "print(f\"Decision Tree Accuracy: {accuracy_dt}\")\n",
        "print(\"Classification Report for Decision Tree:\")\n",
        "print(classification_report_dt)\n",
        "\n",
        "# Model:3 Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize and train the Random Forest model\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "classification_report_rf = classification_report(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Random Forest Accuracy: {accuracy_rf}\")\n",
        "print(\"Classification Report for Random Forest:\")\n",
        "print(classification_report_rf)"
      ],
      "metadata": {
        "id": "UrBjOpHmKjwB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}